{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1 - Install Dependencies"
      ],
      "metadata": {
        "id": "dK_JBKZ_6G7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs the necessary Python libraries for running the code."
      ],
      "metadata": {
        "id": "dzjYy4P-6mGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8BtcweN6Dco",
        "outputId": "dbc2ac64-5b00-40ad-9a4e-865593d1e39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2 - Import Libraries"
      ],
      "metadata": {
        "id": "n5vAwooP6yJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports the required modules and classes for model handling, data processing, and training."
      ],
      "metadata": {
        "id": "BS02c31h69ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "from transformers import DataCollatorForLanguageModeling"
      ],
      "metadata": {
        "id": "0To2TJu66xY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3 - Load or Reuse Model and Tokenizer"
      ],
      "metadata": {
        "id": "NkBAhxrd7CIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads the GPT-2 medium model and tokenizer, either from a local directory (if previously trained) or from Hugging Face."
      ],
      "metadata": {
        "id": "qsVbRsjE6udI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2-medium\"\n",
        "local_model_path = \"./fine_tuned_story_model\"\n",
        "# Check if fine-tuned model exists locally\n",
        "if os.path.exists(local_model_path):\n",
        "    print(\"Loading fine-tuned model from local directory...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(local_model_path)\n",
        "else:\n",
        "    print(\"Loading pre-trained model from Hugging Face...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    # Set padding token\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--UDAe5d7O4v",
        "outputId": "38a6e2a2-ca44-40c0-b6af-e6c629de29bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading fine-tuned model from local directory...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1024)\n",
              "    (wpe): Embedding(1024, 1024)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=3072, nx=1024)\n",
              "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
              "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4 - Load and Prepare Dataset (Only Needed for Training)"
      ],
      "metadata": {
        "id": "hr6H0DYp7fFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads and preprocesses the \"TinyStories\" dataset for training the model."
      ],
      "metadata": {
        "id": "eW6sayOT7rvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_data():\n",
        "    dataset = load_dataset(\"roneneldan/TinyStories\")\n",
        "    train_data = dataset['train'].select(range(20000))  # 20k samples\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        formatted_texts = [f\"Story Start: {text}\" for text in examples['text']]\n",
        "        return tokenizer(formatted_texts,\n",
        "                        truncation=True,\n",
        "                        padding='max_length',\n",
        "                        max_length=300)\n",
        "\n",
        "    tokenized_dataset = train_data.map(preprocess_function,\n",
        "                                     batched=True,\n",
        "                                     remove_columns=['text'])\n",
        "\n",
        "    train_size = int(0.9 * len(tokenized_dataset))\n",
        "    train_dataset = tokenized_dataset.select(range(train_size))\n",
        "    eval_dataset = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))\n",
        "    return train_dataset, eval_dataset\n"
      ],
      "metadata": {
        "id": "US8VA-Kf7x59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5 - Training Setup (Run Only if Training is Needed)"
      ],
      "metadata": {
        "id": "BLGAvs2J71Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configures and runs the training process for fine-tuning the model on the story dataset."
      ],
      "metadata": {
        "id": "y7Ic5fwL8BPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataset, eval_dataset):\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./story_generator\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=1000,\n",
        "        save_steps=1000,\n",
        "        warmup_steps=200,\n",
        "        learning_rate=3e-5,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=200,\n",
        "        fp16=True,\n",
        "        gradient_accumulation_steps=2,\n",
        "        report_to=\"none\"  # Disable W&B logging\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    # Save after training\n",
        "    model.save_pretrained(local_model_path)\n",
        "    tokenizer.save_pretrained(local_model_path)\n",
        "    print(\"Model saved to\", local_model_path)"
      ],
      "metadata": {
        "id": "kIrfS_br8OjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6 - Story Generation Function"
      ],
      "metadata": {
        "id": "F85e9UcK8TVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(prompt, max_length=300, temperature=0.8, top_p=0.9, beams=4):\n",
        "    input_ids = tokenizer.encode(f\"Story Start: {prompt}\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        num_beams=beams,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        do_sample=True,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    story = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    story = story.replace(\"Story Start: \", \"\")\n",
        "    return story\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I7wP-FwjesvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 7 - Main Execution\n"
      ],
      "metadata": {
        "id": "aTEo_1DZ9yKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks if the model needs to be trained, trains it if necessary and generates a story using a predefined prompt."
      ],
      "metadata": {
        "id": "lEzLYHoC9-q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(local_model_path):\n",
        "    print(\"Training model for the first time...\")\n",
        "    train_dataset, eval_dataset = load_and_process_data()\n",
        "    train_model(train_dataset, eval_dataset)\n",
        "else:\n",
        "    print(\"Using pre-trained local model, skipping training...\")\n",
        "\n",
        "# Prompt user for story starter\n",
        "print(\"\\nPlease enter the starting sentence of your story:\")\n",
        "user_prompt = input(\"> \")\n",
        "\n",
        "# Generate and display the story\n",
        "story = generate_story(user_prompt)\n",
        "print(\"\\nGenerated Story:\")\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2tn9MGp2L6G",
        "outputId": "0ce3464b-511e-4c8d-899f-cf0b55310bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pre-trained local model, skipping training...\n",
            "\n",
            "Please enter the starting sentence of your story:\n",
            "> Once upon a time, there was a little dragon who couldn't fly in the sky\n",
            "\n",
            "Generated Story:\n",
            "Once upon a time, there was a little dragon who couldn't fly in the sky. He was sad because he couldn't soar like the other dragons. One day, he met a wise old owl who told him that he could soar if he practiced. The dragon listened to the owl and practiced every day.\n",
            "\n",
            "One day, the dragon met a little bird who was also sad. The bird asked the dragon, \"Why can't you soar like me?\" The dragon thought for a moment and then said, \"Because I don't have wings like you.\"\n",
            "\n",
            "The bird felt sorry for the dragon and wanted to help him. So, the bird flew down to the ground and landed on the dragon's back. Together, they practiced flying together and soon the dragon was soaring like the little bird. From that day on, they became the best of friends. And they lived happily ever after. The end. The moral of the story is that if you practice and practice, you can achieve anything you set your mind to. And you never know, you might just find something even more amazing than you ever imagined!\n",
            "\n",
            "This story teaches us that it's important to practice and to never give up. Even if something seems impossible, if you keep trying and practicing, it will eventually come true. And that's what we should always do, no matter how hard it seems. We should always be grateful for what we have, even if it seems impossible. And we should\n"
          ]
        }
      ]
    }
  ]
}